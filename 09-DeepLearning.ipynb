{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1035b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T18:50:35.374835Z",
     "iopub.status.busy": "2025-04-30T18:50:35.374349Z",
     "iopub.status.idle": "2025-04-30T18:50:35.378428Z",
     "shell.execute_reply": "2025-04-30T18:50:35.377574Z",
     "shell.execute_reply.started": "2025-04-30T18:50:35.374810Z"
    },
    "id": "f1035b53",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_summary = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2eb4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T18:50:35.379808Z",
     "iopub.status.busy": "2025-04-30T18:50:35.379592Z",
     "iopub.status.idle": "2025-04-30T18:50:35.398378Z",
     "shell.execute_reply": "2025-04-30T18:50:35.397645Z",
     "shell.execute_reply.started": "2025-04-30T18:50:35.379792Z"
    },
    "id": "ed2eb4e2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0788b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-04-30T18:50:35.399815Z",
     "iopub.status.busy": "2025-04-30T18:50:35.399614Z",
     "iopub.status.idle": "2025-04-30T18:51:52.653387Z",
     "shell.execute_reply": "2025-04-30T18:51:52.652704Z",
     "shell.execute_reply.started": "2025-04-30T18:50:35.399799Z"
    },
    "id": "4c0788b0",
    "outputId": "60488198-427a-4d1f-eb2c-79a85ff07690",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This code is downloading the notebook from GitHub and running it\n",
    "import requests\n",
    "from pathlib import Path\n",
    "url = \"https://raw.githubusercontent.com/nbakas/NLP/refs/heads/main/02-Preprocessing.ipynb\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "local_path = Path.cwd() / filename\n",
    "if not local_path.exists():\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    local_path.write_bytes(response.content)\n",
    "%run 02-Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff73cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T18:51:52.654751Z",
     "iopub.status.busy": "2025-04-30T18:51:52.654240Z",
     "iopub.status.idle": "2025-04-30T18:51:56.616351Z",
     "shell.execute_reply": "2025-04-30T18:51:56.615584Z",
     "shell.execute_reply.started": "2025-04-30T18:51:52.654724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f2fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T18:51:56.618561Z",
     "iopub.status.busy": "2025-04-30T18:51:56.618178Z",
     "iopub.status.idle": "2025-04-30T18:51:56.622434Z",
     "shell.execute_reply": "2025-04-30T18:51:56.621787Z",
     "shell.execute_reply.started": "2025-04-30T18:51:56.618541Z"
    },
    "id": "c96f2fbd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6e50d",
   "metadata": {
    "id": "aec6e50d"
   },
   "source": [
    "# Example preprocessing: tokenize and build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbf068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:14.215456Z",
     "iopub.status.busy": "2025-04-30T19:07:14.214829Z",
     "iopub.status.idle": "2025-04-30T19:07:14.222225Z",
     "shell.execute_reply": "2025-04-30T19:07:14.221397Z",
     "shell.execute_reply.started": "2025-04-30T19:07:14.215436Z"
    },
    "id": "17bbf068",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    \"\"\"A minimal Dataset for turning raw sentences into fixed-length\n",
    "    sequences of token IDs that can be fed to a neural network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : List[str]\n",
    "        Sentences/documents to be classified.\n",
    "    labels : List[int]\n",
    "        Integer class labels (e.g. 1-5 star ratings).\n",
    "    vocab : Dict[str, int], optional\n",
    "        Pre-built mapping from token → integer index. If *None*, one will\n",
    "        be built from *texts*.\n",
    "    max_len : int, default=20\n",
    "        Sentences longer than *max_len* are truncated; shorter ones are\n",
    "        padded with the <PAD> token so every sample has identical length.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, vocab=None, max_len: int = 20):\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Tokenise each sentence by simple whitespace splitting and make\n",
    "        # everything lowercase so that \"Dog\" and \"dog\" map to the same token.\n",
    "        self.texts = [t.lower().split() for t in texts]\n",
    "        self.labels = labels\n",
    "\n",
    "        if vocab is None:\n",
    "            # Build a frequency counter for all words appearing in the\n",
    "            # training corpus so we can assign them stable indices.\n",
    "            counter = Counter(word for text in self.texts for word in text)\n",
    "\n",
    "            # Reserve *two* indices for special tokens that don't correspond\n",
    "            # to real words. We start ordinary words at index 2 so that 0 and\n",
    "            # 1 are free for these special cases:\n",
    "            #   <PAD> (index 0) — Padding token used purely to make all\n",
    "            #                     sequences the same length within a batch.\n",
    "            #                     It carries *no* semantic meaning. Models\n",
    "            #                     learn to ignore it via masking or by having\n",
    "            #                     an embedding vector that is not updated.\n",
    "            #   <UNK> (index 1) — «UNKnown» token assigned to any word that\n",
    "            #                     was *not* present in the vocabulary at the\n",
    "            #                     time of building/training. Collapsing every\n",
    "            #                     unseen word to a single ID keeps the\n",
    "            #                     vocabulary compact and protects the model\n",
    "            #                     from crashing when it encounters an\n",
    "            #                     out-of-vocabulary term at test time.\n",
    "            # The self.vocab is a dictionary that maps each word to its corresponding index in the vocabulary.\n",
    "            # The vocabulary is built from the most common words in the training corpus. If input n of most_common is None, then list all element counts.\n",
    "            # The most_common method returns a list of tuples, where each tuple contains a word and its count in the corpus.\n",
    "            # The enumerate function is used to pair each word with its index in the vocabulary.\n",
    "            # The +2 is used to reserve the first two indices for the special tokens <PAD> and <UNK>.\n",
    "            self.vocab = {word: idx + 2 for idx, (word, _) in enumerate(counter.most_common())}\n",
    "            self.vocab['<PAD>'] = 0\n",
    "            # The <PAD> and <UNK> tokens are assigned indices 0 and 1 respectively.\n",
    "            self.vocab['<UNK>'] = 1\n",
    "        else:\n",
    "            # If the vocabulary is already built, then use the pre-built vocabulary.\n",
    "            self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        \"\"\"Convert a tokenised *text* (list of str) into a tensor of IDs, which is a tensor of shape (max_len,) and is useful for feeding into the pytorch model.\n",
    "\n",
    "        Any word that is not in *self.vocab* maps to the <UNK> index so that\n",
    "        the network receives *some* vector rather than crashing. If the\n",
    "        resulting sequence is shorter than *max_len* we append <PAD> IDs\n",
    "        until it reaches the desired length; if it is longer we truncate the\n",
    "        tail. The output is therefore always of shape (max_len,).\n",
    "        \"\"\"\n",
    "\n",
    "        # Map every word to its ID, defaulting to <UNK> (1) when necessary.\n",
    "        ids = [self.vocab.get(word, self.vocab['<UNK>']) for word in text]\n",
    "\n",
    "        # Pad or truncate to fixed length so that we can stack multiple\n",
    "        # samples into a single tensor of shape (batch_size, max_len).\n",
    "        if len(ids) < self.max_len:\n",
    "            # Add as many <PAD> (0) tokens as needed.\n",
    "            ids += [self.vocab['<PAD>']] * (self.max_len - len(ids))\n",
    "        else:\n",
    "            ids = ids[: self.max_len]\n",
    "\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the already-tokenised sentence and convert it to IDs.\n",
    "        text_tensor = self.encode_text(self.texts[idx])\n",
    "\n",
    "        # Adjust label range from 1-5 → 0-4 because PyTorch's\n",
    "        # CrossEntropyLoss expects class IDs starting at 0.\n",
    "        label_tensor = torch.tensor(self.labels[idx] - 1)\n",
    "\n",
    "        return text_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec97bb",
   "metadata": {
    "id": "d5ec97bb"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8425209",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:14.904984Z",
     "iopub.status.busy": "2025-04-30T19:07:14.904486Z",
     "iopub.status.idle": "2025-04-30T19:07:14.912274Z",
     "shell.execute_reply": "2025-04-30T19:07:14.911455Z",
     "shell.execute_reply.started": "2025-04-30T19:07:14.904962Z"
    },
    "id": "f8425209",
    "outputId": "20a258e7-421e-4645-c9e6-b0bec15ba82e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is the class for the deep learning model. nn.Module is the parent class for all neural network modules in PyTorch.\n",
    "class DLModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, # This is the self parameter, which is the instance of the class\n",
    "        vocab_size, # This is the size of the vocabulary\n",
    "        embed_dim, # This is the dimension of the embedding layer\n",
    "        hidden_dim, # This is the dimension of the hidden layer\n",
    "        output_dim, # This is the dimension of the output layer\n",
    "        model_type='RNN', # This is the type of the model\n",
    "        num_layers=1, # This is the number of layers in the model\n",
    "        dropout_prob=0.5 # This is the dropout probability\n",
    "    ):\n",
    "        super().__init__() # This is the super() function, which is the parent class of the class\n",
    "        # Initialize the embedding layer with the given vocabulary size and embedding dimension\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "        # Initialize the recurrent layer based on the specified model type\n",
    "        if model_type == 'RNN':\n",
    "            # Use RNN with specified parameters\n",
    "            self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                              dropout=dropout_prob if num_layers > 1 else 0, batch_first=True)\n",
    "        elif model_type == 'LSTM':\n",
    "            # Use LSTM with specified parameters\n",
    "            self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                               dropout=dropout_prob if num_layers > 1 else 0, batch_first=True)\n",
    "        elif model_type == 'GRU':\n",
    "            # Use GRU with specified parameters\n",
    "            self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                              dropout=dropout_prob if num_layers > 1 else 0, batch_first=True)\n",
    "        else:\n",
    "            # Raise an error if an unsupported model type is provided\n",
    "            raise ValueError('model_type must be RNN, LSTM, or GRU')\n",
    "\n",
    "        # Initialize batch normalization for the hidden layer\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        # Initialize dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # Initialize the fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embed the input sequence\n",
    "        embedded = self.embedding(x)  # Shape: [batch_size, seq_len, embed_dim]\n",
    "        # Pass the embedded sequence through the recurrent layer\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        # Check if the hidden state is a tuple (for LSTM)\n",
    "        if isinstance(hidden, tuple):  # For LSTM\n",
    "            hidden = hidden[0]  # Use the hidden state, not the cell state\n",
    "\n",
    "        # Use the last layer's hidden state\n",
    "        hidden = hidden[-1]  # Shape: [batch_size, hidden_dim]\n",
    "        # Apply batch normalization\n",
    "        hidden = self.batch_norm(hidden)  # BatchNorm expects shape [batch_size, features]\n",
    "        # Apply dropout for regularization\n",
    "        hidden = self.dropout(hidden)\n",
    "        # Pass through the fully connected layer to get the output\n",
    "        out = self.fc(hidden)\n",
    "        return out  # Return the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9029a",
   "metadata": {
    "id": "a7b9029a"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864a2b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:17.340091Z",
     "iopub.status.busy": "2025-04-30T19:07:17.339500Z",
     "iopub.status.idle": "2025-04-30T19:07:17.368270Z",
     "shell.execute_reply": "2025-04-30T19:07:17.367538Z",
     "shell.execute_reply.started": "2025-04-30T19:07:17.340069Z"
    },
    "id": "4864a2b3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the 'df_summary' column of the DataFrame to a list of texts\n",
    "texts = df_summary.tolist()\n",
    "# Display the first 5 elements of the list for inspection\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad17e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:18.668187Z",
     "iopub.status.busy": "2025-04-30T19:07:18.667479Z",
     "iopub.status.idle": "2025-04-30T19:07:18.679944Z",
     "shell.execute_reply": "2025-04-30T19:07:18.679226Z",
     "shell.execute_reply.started": "2025-04-30T19:07:18.668160Z"
    },
    "id": "6ad17e9d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the 'df_score' column of the DataFrame to a list of integer labels\n",
    "labels = df_score.astype(int).tolist()\n",
    "# Display the first 5 elements of the labels list for inspection\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7ace9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:20.470816Z",
     "iopub.status.busy": "2025-04-30T19:07:20.470571Z",
     "iopub.status.idle": "2025-04-30T19:07:20.739627Z",
     "shell.execute_reply": "2025-04-30T19:07:20.738844Z",
     "shell.execute_reply.started": "2025-04-30T19:07:20.470800Z"
    },
    "id": "7cc7ace9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# 'train_test_split' is used to randomly partition the data\n",
    "# 'texts' and 'labels' are split into training and testing subsets\n",
    "# 'test_size=0.2' indicates 20% of the data will be used for testing\n",
    "# 'random_state=42' ensures reproducibility of the split\n",
    "# 'stratify=labels' ensures the class distribution is preserved in both sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de476d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:21.872825Z",
     "iopub.status.busy": "2025-04-30T19:07:21.872579Z",
     "iopub.status.idle": "2025-04-30T19:07:22.075512Z",
     "shell.execute_reply": "2025-04-30T19:07:22.074757Z",
     "shell.execute_reply.started": "2025-04-30T19:07:21.872809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We will not use the full max_len. \n",
    "# Let’s say our longest review title is 120 words, but 95% are under 25.\n",
    "# Using max_len=120 wastes computation and memory on padding for most inputs.\n",
    "# Long sequences may slow down training and cause overfitting.\n",
    "# It makes batches less dense (more padding = less useful gradient info).\n",
    "# Hence we will use the 95th percentile of the lengths. This gives you a smart cap on sequence length, keeping training efficient without losing too much signal from long examples.\n",
    "lengths = [len(t.lower().split()) for t in train_texts]\n",
    "max_len = int(np.percentile(lengths, 95))  # or max(lengths) if you want the absolute max\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wrk25WQpj9hw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:25.578674Z",
     "iopub.status.busy": "2025-04-30T19:07:25.578396Z",
     "iopub.status.idle": "2025-04-30T19:07:27.391902Z",
     "shell.execute_reply": "2025-04-30T19:07:27.391347Z",
     "shell.execute_reply.started": "2025-04-30T19:07:25.578654Z"
    },
    "id": "Wrk25WQpj9hw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_texts, train_labels, max_len=max_len)\n",
    "test_dataset = TextDataset(test_texts, test_labels, vocab=train_dataset.vocab, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435f900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:27.393236Z",
     "iopub.status.busy": "2025-04-30T19:07:27.392990Z",
     "iopub.status.idle": "2025-04-30T19:07:27.397079Z",
     "shell.execute_reply": "2025-04-30T19:07:27.396562Z",
     "shell.execute_reply.started": "2025-04-30T19:07:27.393215Z"
    },
    "id": "e435f900",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1a59c",
   "metadata": {
    "id": "5ce1a59c"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ff6a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:28.271362Z",
     "iopub.status.busy": "2025-04-30T19:07:28.270640Z",
     "iopub.status.idle": "2025-04-30T19:07:28.275166Z",
     "shell.execute_reply": "2025-04-30T19:07:28.274248Z",
     "shell.execute_reply.started": "2025-04-30T19:07:28.271338Z"
    },
    "id": "6a2ff6a4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine the size of the vocabulary from the training dataset\n",
    "vocab_size = len(train_dataset.vocab)\n",
    "# Set the embedding dimension for the model\n",
    "embed_dim = 384\n",
    "# Set the hidden layer dimension for the model\n",
    "hidden_dim = 256\n",
    "# Define the output dimension, corresponding to the number of classes (1-5 stars)\n",
    "output_dim = 5  # 5 classes (1-5 stars)\n",
    "# Specify the type of model to use; options include 'RNN', 'LSTM', or 'GRU'\n",
    "model_type = 'LSTM'  # <-- CHANGE HERE to 'RNN' or 'LSTM' or 'GRU'\n",
    "# Set the number of layers in the model\n",
    "number_of_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6135e",
   "metadata": {
    "id": "78c6135e"
   },
   "source": [
    "# Model, loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea078934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:29.878407Z",
     "iopub.status.busy": "2025-04-30T19:07:29.878103Z",
     "iopub.status.idle": "2025-04-30T19:07:29.883580Z",
     "shell.execute_reply": "2025-04-30T19:07:29.882890Z",
     "shell.execute_reply.started": "2025-04-30T19:07:29.878386Z"
    },
    "id": "ea078934",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU support) is available and set the device accordingly\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Display the device being used (either 'cuda' for GPU or 'cpu' for CPU)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c6f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:33.790364Z",
     "iopub.status.busy": "2025-04-30T19:07:33.790054Z",
     "iopub.status.idle": "2025-04-30T19:07:33.935143Z",
     "shell.execute_reply": "2025-04-30T19:07:33.934537Z",
     "shell.execute_reply.started": "2025-04-30T19:07:33.790344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the deep learning model with the specified parameters:\n",
    "# - vocab_size: size of the vocabulary from the training dataset\n",
    "# - embed_dim: dimension of the embedding layer\n",
    "# - hidden_dim: dimension of the hidden layer\n",
    "# - output_dim: number of output classes (1-5 stars)\n",
    "# - model_type: type of model to use ('RNN', 'LSTM', or 'GRU')\n",
    "# - num_layers: number of layers in the model\n",
    "# Move the model to the specified device (GPU if available, otherwise CPU)\n",
    "model = DLModel(vocab_size, embed_dim, hidden_dim, output_dim, model_type, num_layers=number_of_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845d9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:35.141660Z",
     "iopub.status.busy": "2025-04-30T19:07:35.140961Z",
     "iopub.status.idle": "2025-04-30T19:07:35.145313Z",
     "shell.execute_reply": "2025-04-30T19:07:35.144463Z",
     "shell.execute_reply.started": "2025-04-30T19:07:35.141637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The criterion is the loss function used to evaluate the performance of the model during training.\n",
    "# It measures the difference between the predicted outputs and the actual target values.\n",
    "# In this context, we are using CrossEntropyLoss, which is suitable for multi-class classification problems.\n",
    "# This loss function computes the cross-entropy loss between the predicted class probabilities and the true class labels.\n",
    "# It is particularly effective for tasks where the model outputs a probability distribution over multiple classes.\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66ddc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:37.785589Z",
     "iopub.status.busy": "2025-04-30T19:07:37.784987Z",
     "iopub.status.idle": "2025-04-30T19:07:37.789387Z",
     "shell.execute_reply": "2025-04-30T19:07:37.788654Z",
     "shell.execute_reply.started": "2025-04-30T19:07:37.785566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the optimizer for the model's parameters using the Adam optimization algorithm.\n",
    "# Adam is an adaptive learning rate optimization algorithm that's been designed specifically for training deep neural networks.\n",
    "# It combines the advantages of two other extensions of stochastic gradient descent: AdaGrad and RMSProp.\n",
    "# This optimizer will adjust the learning rate for each parameter dynamically, which can lead to faster convergence.\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a5c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:44.618779Z",
     "iopub.status.busy": "2025-04-30T19:07:44.618512Z",
     "iopub.status.idle": "2025-04-30T19:07:44.622526Z",
     "shell.execute_reply": "2025-04-30T19:07:44.621792Z",
     "shell.execute_reply.started": "2025-04-30T19:07:44.618758Z"
    },
    "id": "413a5c3f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the number of epochs for training the model\n",
    "# An epoch is one complete forward and backward pass of all the training examples\n",
    "# More epochs can lead to better training but may also cause overfitting\n",
    "nof_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8327f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:45.596245Z",
     "iopub.status.busy": "2025-04-30T19:07:45.595730Z",
     "iopub.status.idle": "2025-04-30T19:07:45.603464Z",
     "shell.execute_reply": "2025-04-30T19:07:45.602740Z",
     "shell.execute_reply.started": "2025-04-30T19:07:45.596225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, test_loader, criterion, device, train_accuracies, test_accuracies, test_losses, epoch, train_loss):\n",
    "    # Initialize variables to track test loss and correct predictions\n",
    "    test_loss = 0\n",
    "    correct_train = 0\n",
    "    correct_test = 0\n",
    "    total_train = 0\n",
    "    total_test = 0\n",
    "\n",
    "    # Calculate train accuracy\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device\n",
    "            outputs = model(inputs)  # Forward pass: compute model output\n",
    "            preds = outputs.argmax(dim=1)  # Get predicted class by finding the index of the max log-probability\n",
    "            correct_train += (preds == targets).sum().item()  # Count correct predictions\n",
    "            total_train += targets.size(0)  # Count total samples\n",
    "    train_accuracy = correct_train / total_train  # Calculate train accuracy\n",
    "    train_accuracies.append(train_accuracy)  # Append train accuracy to the list\n",
    "\n",
    "    # Calculate test loss and accuracy\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device\n",
    "            outputs = model(inputs)  # Forward pass: compute model output\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            test_loss += loss.item()  # Accumulate test loss\n",
    "            preds = outputs.argmax(dim=1)  # Get predicted class by finding the index of the max log-probability\n",
    "            correct_test += (preds == targets).sum().item()  # Count correct predictions\n",
    "            total_test += targets.size(0)  # Count total samples\n",
    "    test_loss /= len(test_loader)  # Average test loss over all batches\n",
    "    test_losses.append(test_loss)  # Append test loss to the list\n",
    "    test_accuracy = correct_test / total_test  # Calculate test accuracy\n",
    "    test_accuracies.append(test_accuracy)  # Append test accuracy to the list\n",
    "\n",
    "    print(100*\"=\")  # Print separator for readability\n",
    "    # Print current epoch, train loss, test loss, train accuracy, and test accuracy\n",
    "    print(f\"{datetime.now().replace(microsecond=0)}, Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(100*\"=\")  # Print separator for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c4a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:47.434143Z",
     "iopub.status.busy": "2025-04-30T19:07:47.433621Z",
     "iopub.status.idle": "2025-04-30T19:07:47.437614Z",
     "shell.execute_reply": "2025-04-30T19:07:47.436853Z",
     "shell.execute_reply.started": "2025-04-30T19:07:47.434097Z"
    },
    "id": "bc8c4a2f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the time module to work with time-related functions\n",
    "import time\n",
    "# Record the current time to measure the elapsed time during training\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3ac3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:47.724061Z",
     "iopub.status.busy": "2025-04-30T19:07:47.723578Z",
     "iopub.status.idle": "2025-04-30T19:07:47.727576Z",
     "shell.execute_reply": "2025-04-30T19:07:47.726985Z",
     "shell.execute_reply.started": "2025-04-30T19:07:47.724037Z"
    },
    "id": "9bf3ac3c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store training and testing accuracies for each epoch\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Initialize lists to store training and testing losses for each epoch\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06b1aa",
   "metadata": {},
   "source": [
    "# Initial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = sum(criterion(model(inputs.to(device)), targets.to(device)).item() for inputs, targets in train_loader) / len(train_loader)\n",
    "train_losses.append(train_loss)\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33563fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, train_loader, test_loader, criterion, device, train_accuracies, test_accuracies, test_losses, -1, train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41440ce8",
   "metadata": {
    "id": "41440ce8"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5kpgkWGbp02W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-30T19:07:49.465838Z",
     "iopub.status.busy": "2025-04-30T19:07:49.465364Z",
     "iopub.status.idle": "2025-04-30T19:11:01.243550Z",
     "shell.execute_reply": "2025-04-30T19:11:01.242763Z",
     "shell.execute_reply.started": "2025-04-30T19:07:49.465814Z"
    },
    "id": "5kpgkWGbp02W",
    "outputId": "27c48f44-53aa-4d2d-80c9-8eacf43dc7e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loop over each epoch\n",
    "for epoch in range(nof_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0  # Initialize training loss for the current epoch\n",
    "    # Loop over each batch in the training data\n",
    "    for idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients for the optimizer\n",
    "        outputs = model(inputs)  # Forward pass: compute model output\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backward pass: compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        # Print progress every 10% of the training data\n",
    "        if idx % (len(train_loader) // 10) == 0:\n",
    "           print(f\"{datetime.now().replace(microsecond=0)}, Epoch {epoch+1}, Batch {idx+1}/{len(train_loader)}, Train Loss: {train_loss/(idx+1):.4f}, Elapsed: {(time.time() - start_time)/60:.5f} min\")\n",
    "    train_loss = train_loss / len(train_loader)  # Average training loss over all batches\n",
    "    train_losses.append(train_loss)  # Append training loss to the list\n",
    "\n",
    "    # Evaluate the model on training and test data\n",
    "    evaluate_model(model, train_loader, test_loader, criterion, device, train_accuracies, test_accuracies, test_losses, epoch, train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86556a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:19:26.827992Z",
     "iopub.status.busy": "2025-04-30T19:19:26.827229Z",
     "iopub.status.idle": "2025-04-30T19:19:27.096946Z",
     "shell.execute_reply": "2025-04-30T19:19:27.096260Z",
     "shell.execute_reply.started": "2025-04-30T19:19:26.827972Z"
    },
    "id": "86556a56",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting\n",
    "\n",
    "# Plot training and test loss\n",
    "plt.figure(figsize=(10, 2))  # Create a new figure with a specified size\n",
    "plt.plot(train_losses, label='Train Loss')  # Plot the training loss with a label\n",
    "plt.plot(test_losses, label='Test Loss')  # Plot the test loss with a label\n",
    "plt.title('Loss over Epochs')  # Set the title of the plot\n",
    "plt.xlabel('Epoch')  # Set the x-axis label\n",
    "plt.ylabel('Loss')  # Set the y-axis label\n",
    "plt.legend()  # Display the legend to differentiate between plots\n",
    "plt.show()  # Show the plot\n",
    "\n",
    "# Plot training and test accuracy\n",
    "plt.figure(figsize=(10, 2))  # Create another figure for accuracy plots\n",
    "plt.plot(train_accuracies, label='Train Accuracy')  # Plot the training accuracy with a label\n",
    "plt.plot(test_accuracies, label='Test Accuracy')  # Plot the test accuracy with a label\n",
    "plt.title('Accuracy over Epochs')  # Set the title of the accuracy plot\n",
    "plt.xlabel('Epoch')  # Set the x-axis label for accuracy\n",
    "plt.ylabel('Accuracy')  # Set the y-axis label for accuracy\n",
    "plt.legend()  # Display the legend for accuracy plots\n",
    "plt.show()  # Show the accuracy plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070b4ca",
   "metadata": {
    "id": "5070b4ca"
   },
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3a996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:19:34.296191Z",
     "iopub.status.busy": "2025-04-30T19:19:34.295585Z",
     "iopub.status.idle": "2025-04-30T19:19:36.042720Z",
     "shell.execute_reply": "2025-04-30T19:19:36.041922Z",
     "shell.execute_reply.started": "2025-04-30T19:19:34.296164Z"
    },
    "id": "f8b3a996",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report  # Import classification_report from sklearn.metrics for evaluation\n",
    "\n",
    "# Test + collect predictions\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_preds = []  # Initialize a list to store all predictions\n",
    "all_targets = []  # Initialize a list to store all true targets\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "    for inputs, targets in test_loader:  # Iterate over the test data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device\n",
    "        outputs = model(inputs)  # Get model outputs\n",
    "        preds = outputs.argmax(dim=1)  # Get predicted class by finding the index of the max log-probability\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())  # Append predictions to the list, converting to numpy array\n",
    "        all_targets.extend(targets.cpu().numpy())  # Append true targets to the list, converting to numpy array\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_targets, all_preds, digits=4))  # Print a detailed classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad722b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T19:19:36.295077Z",
     "iopub.status.busy": "2025-04-30T19:19:36.294830Z",
     "iopub.status.idle": "2025-04-30T19:19:43.446302Z",
     "shell.execute_reply": "2025-04-30T19:19:43.445680Z",
     "shell.execute_reply.started": "2025-04-30T19:19:36.295060Z"
    },
    "id": "b9ad722b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report  # Import classification_report for evaluating model performance\n",
    "\n",
    "# Train + collect predictions\n",
    "model.eval()  # Set the model to evaluation mode to disable dropout and batch normalization\n",
    "\n",
    "all_preds = []  # Initialize a list to store predictions from the model\n",
    "all_targets = []  # Initialize a list to store true target values\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for efficiency during evaluation\n",
    "    for inputs, targets in train_loader:  # Iterate over the training data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to the specified device (CPU or GPU)\n",
    "        outputs = model(inputs)  # Get model outputs for the inputs\n",
    "        preds = outputs.argmax(dim=1)  # Determine predicted class by finding the index of the max log-probability\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())  # Append predictions to the list, converting to numpy array\n",
    "        all_targets.extend(targets.cpu().numpy())  # Append true targets to the list, converting to numpy array\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_targets, all_preds, digits=4))  # Print a detailed classification report with 4 decimal places\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2157,
     "datasetId": 18,
     "sourceId": 2157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
